{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import random\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# Set the environment variable for Hugging Face API token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Initialize the LLM with the specified parameters\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    temperature=0.5,\n",
    "    max_length=1024,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "\n",
    "# Define the Hugging Face API URL and headers for image generation\n",
    "API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def create_payload(prompt, seed):\n",
    "    return {\n",
    "        \"inputs\": prompt,\n",
    "        \"options\": {\n",
    "            \"seed\": seed\n",
    "        }\n",
    "    }\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response\n",
    "\n",
    "def save_image(image_bytes, file_name):\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        image.save(file_name)  # Save the image\n",
    "        return file_name\n",
    "    except IOError:\n",
    "        print(\"Cannot identify image file\")\n",
    "        return None\n",
    "\n",
    "# Function to extract content after a specified marker\n",
    "def extract_content_after_marker(text, marker):\n",
    "    marker_position = text.find(marker)\n",
    "    if marker_position != -1:\n",
    "        return text[marker_position + len(marker):].strip()\n",
    "    return \"Marker not found in text.\"\n",
    "\n",
    "# Define the process_llm function\n",
    "def process_llm(article_text, url):\n",
    "    examples = [\n",
    "        {\n",
    "            \"title\": \"this is example 1üöÄ Transforming Digital Marketing in 2024! üöÄ\",\n",
    "            \"description\": \"\"\"I am excited to share my latest article on the future of digital marketing. In this piece, we explore the latest trends, including AI-driven analytics, personalized content strategies, and multi-channel engagement.\n",
    "\n",
    "    ‚ú® Highlights include:\n",
    "    - The rise of AI in marketing\n",
    "    - Personalized customer journeys\n",
    "    - Effective multi-channel strategies\n",
    "\n",
    "    This is a must-read for marketers looking to stay ahead of the game!\n",
    "\n",
    "    üëâ Read the full article here: [link]\n",
    "\n",
    "    #DigitalMarketing #MarketingTrends #AI #Personalization #Innovation #2024Trends\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"this is example 2üåü Revolutionizing Healthcare with Technology üåü\",\n",
    "            \"description\": \"\"\"Check out my new article on how technology is transforming healthcare. We delve into groundbreaking advancements such as telemedicine, AI diagnostics, and personalized treatment plans.\n",
    "\n",
    "    üîç Key points covered:\n",
    "    - The growth of telemedicine\n",
    "    - AI in disease diagnosis\n",
    "    - Personalized healthcare solutions\n",
    "\n",
    "    Healthcare professionals, don't miss out on these insights!\n",
    "\n",
    "    üëâ Read more: [link]\n",
    "\n",
    "    #Healthcare #HealthTech #AIinHealthcare #Telemedicine #Innovation #MedicalTrends\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"title\", \"description\"],\n",
    "        template=\"{title}\\n\\n{description}\"\n",
    "    )\n",
    "\n",
    "    prompt = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=\"Read the following article text and create a LinkedIn post description that highlights the key points and insights. The post should be engaging, professional, and encourage readers to read the full article. Include a call-to-action and relevant hashtags. Below are examples of similar posts. aslo in place of link add the url given\",\n",
    "        suffix=\"Your Turn:\\n\\nArticle Text:\\n\\n{article_text}\\n\\nURL of the article: {url}\",\n",
    "        input_variables=[\"article_text\", \"url\"]\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt.format(article_text=article_text, url=url)\n",
    "    res = llm.invoke(final_prompt)\n",
    "\n",
    "    marker_text = \"LinkedIn Post:\"\n",
    "    content_after_marker = extract_content_after_marker(res, marker_text)\n",
    "\n",
    "    prompt_2 = f\"{content_after_marker} form a simple prompt for a text to image model to generate an image with simple imagination avoid text for this linkedin description given above, just give the prompt do not generate pictures urself\"\n",
    "    prompt_image = llm.invoke(prompt_2).strip()\n",
    "\n",
    "    image_files = []\n",
    "    for i in range(3):\n",
    "        seed = random.randint(0, 1000000)  # Generate a random seed\n",
    "        payload = create_payload(prompt_image, seed)\n",
    "        response = query(payload)\n",
    "        if response.status_code == 200:\n",
    "            image_bytes = response.content\n",
    "            file_name = f\"image_{i+1}.png\"\n",
    "            saved_file = save_image(image_bytes, file_name)\n",
    "            if saved_file:\n",
    "                image_files.append(saved_file)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve image. Status code: {response.status_code}\")\n",
    "            print(response.text)  # Print the error message if any\n",
    "\n",
    "    return res, image_files\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
